---
title: "CrossValidation"
author: "Khang Vinh Tran"
date: "7/19/2017"
output: html_document
---
```{r}
# source all the neccesaary files and script
source(file = "ipak.R") # ipak developed by Steven Worthington:
#https://gist.github.com/stevenworthington/3178163

# rattle package requires separate installation. After running install.packages(), select "y" as being prompted
#install.packages("rattle")
# Create a vector of library needed and attach them to the session with ipak()
libraryList <- c("devtools","tidyverse", "tibble", "synthpop","gridExtra", "data.table", "dplyr", "caret",
                 "rpart","rpart.plot", "RColorBrewer", "ROCR", "pROC")
ipak(libraryList)

source("fancyRPartPlot.R") # fancyRpartPlot developed by gjwgit: https://github.com/cran/rattle/blob/master/R/fancyRpartPlot.R
# source the Synthetic Data Generation script
source(file = "rmd2rscript.R")
#rmd2rscript(infile = "Synthetic_Data_Generation.Rmd")
source(file = "Synthetic_Data_Generation.R")
```

```{r}
# define an array of variables' names
vars <- c("AM Stress", "AM Hunger", "AM Sleep", "AM Sleep hours", "AM Weight",
          "Percent Weight change (from prev week)", "Percent Weight change (from prev day)",
          "PM Stress", "EVE Stress", "Number of Episodes Previous Day",
          "Episode" )	
```


```{r}
main.Path <- "/Users/KVTran/Documents/Research/WPI/Slip_Buddy/REU_2017/data"
K = 5
M = 40  #  40 TALK ABOUT THE LEVEL OF M THAT WILL UP THE ACCURACY 
my.Seed = 1
set.seed(my.Seed)

# set this as a default argument
vars <- c("AM Stress", "AM Hunger", "AM Sleep", "AM Sleep hours", "AM Weight", "Percent Weight change (from prev week)", "Percent Weight change (from prev day)","PM Stress", "EVE Stress", "Number of Episodes Previous Day", "Episode" )



# CREATE THE FIRST LAYER OF FOLDER (test, train, train_synth, result, result_synth)
indi.Path <- file.path(main.Path, "Individual_Patient")
test.Path <- file.path(main.Path, "Test")
train.Path <- file.path(main.Path, "Train")
trainSynth.Path <- file.path(main.Path, "Train_Synth")
result.Path <- file.path(main.Path, "Result")
#ResultSynth.Path <- file.path(main.Path, "Result_Synth")
Paths <- c(test.Path, train.Path, trainSynth.Path, result.Path)
for (path in Paths)
{
  dir.create(path, showWarnings = FALSE)
}



# COLLECT ALL THE NAMES OF THE OBSERVED DATA FILES
file.Names <- list.files(path = indi.Path, pattern = "*.csv")
len <- length(file.Names)
for (i in 1:len)   # LEN IS THE NUMBER OF DATASETS (EACH PATIENT HAS ONE DATASET)
{
  # CREATE THE SECOND LAYER OF FOLDERS
  for (path in Paths)
  {
    dir.create(file.path(path, gsub(".csv", "", file.Names[i])), showWarnings = FALSE)
  }
  
  # READ IN THE OBSERVED DATA 
  full.Path <- file.path(indi.Path, file.Names[i])
  assign(x = file.Names[i], value = read.csv(full.Path, check.names = FALSE))
  ods <- get(file.Names[i])
  ods <- ods[,vars]
  ods <- adjustToFactor(ods)
  # CREATE INDICES FOR CROSS VALIDATION FOLDS
  indices.List <- createFolds(y = ods$Episode, k = K)
  # GET THE LIST FOR ALL FOLD NAMES (FOLD1, FOLD2, FOLD3, ...)
  foldNames.List <- names(indices.List)
  
  # CREATE THE EMPTY RESULT TABLE FOR THIS PATIENT HERE
  result.Cols <- c("Accuracy", "AccuracySynth",
                  "Precision", "PrecisionSynth",
                  "Recall","RecallSynth",
                  "Fallout", "FalloutSynth",
                  "FMeasure", "FMeasureSynth",
                  "AUC", "AUCSynth")
  Result <- data.frame()

  for (j in 1:K)  # K IS THE NUMBER OF FOLDS
  {
    indices <- as.numeric(unlist(indices.List[j]))
    foldName <- foldNames.List[j]
    # CREATE AND AND WRITE TEST
    test <- ods[indices, ]
    write.csv(x = test, 
              file = file.path(test.Path,
                               gsub(".csv", "", file.Names[i]),
                               paste(foldName, ".csv", sep = "")),
              row.names = FALSE)
    # CREATE AND WRITE TRAIN FILE
    train <- ods[-indices, ]
    write.csv(x = train, 
              file = file.path(train.Path,
                               gsub(".csv", "", file.Names[i]),
                               paste(foldName, ".csv", sep = "")),
              row.names = FALSE)
    # CREATE AND WRITE THE SYNTHETIC TEST FILE
    sds <- syn(data = train, m = M, seed = my.Seed)
    trainSynth <- data.frame()
    for (k in 1:M)  # M IS THE NUMBER OF SYNTHETIC SET CREATED
    {
      df <- as.data.frame(sds$syn[k])
      colnames(df) <- vars
      df <- adjustToFactor(df)
      trainSynth <- rbind(trainSynth, df)
    }
    write.csv(x = trainSynth, 
              file = file.path(trainSynth.Path,
                               gsub(".csv", "", file.Names[i]),
                               paste(foldName, ".csv", sep = "")),
              row.names = FALSE) 
    # RUN THE MODEL HERE, APPEND THE TEST RECORD (1 ROW) TO THE RESULT TABLE
    print(file.Names[i])
    print(foldName)
    fold.Result <- Test_Each_Fold(test, train, trainSynth, result.Cols)
    Result <- rbind(Result, fold.Result)
  }
  # WRITE THE RESULT TABLE HERE
  write.csv(x = Result,
            file = file.path(result.Path, gsub(".csv", "", file.Names[i]), "Result.csv"),
            row.names = FALSE)
}
```




```{r}

result.Cols <- c("Accuracy", "AccuracySynth",
                "Precision", "PrecisionSynth",
                "Recall","RecallSynth",
                "Fallout", "FalloutSynth",
                "FMeasure", "FMeasureSynth",
                "AUC", "AUCSynth")
Result <- data.frame(matrix(ncol = length(result.Cols)))
colnames(x = Result) <- result.Cols



Test_Each_Fold <- function(test, train, trainSynth, result.Cols)
{
  fold.Result <- data.frame(matrix(0 ,nrow = 1, ncol = length(result.Cols)))
  colnames(fold.Result) <- result.Cols
  CP = 0.01
  CONTROL <- rpart.control(cp = CP)
  start.Index = 1
  train.List <- list(train, trainSynth)
  for (train.Set in train.List)
  {
    tree <- rpart(Episode ~ ., train.Set, method = "class", control = CONTROL)
    preds <- predict(object = tree, newdata = test, type = "class" )
    conf <- table(test$Episode, preds)
    #print(conf)
    # calculate and append accuracy
    acc <- sum(diag(conf)) / (sum(conf))
    fold.Result[,start.Index] = acc
    # calculate and append precision
    prec <- conf[1,1] / (sum(conf[,1])) 
    fold.Result[, start.Index + 2] = prec
    # calculate and append recall
    recall <- conf[1,1] / (sum(conf[1,]))
    fold.Result[,start.Index + 4] = recall
    # calculate and append fallout
    fallout <- conf[2,1]/(sum(conf[2,]))
    fold.Result[,start.Index + 6] = fallout
    # calculate the other Performance measurements:
    FMeasure <- 2*(prec * recall) / (prec + recall)
    fold.Result[,start.Index + 8] = FMeasure
    
    # CALCULATE AUC
    pred <- as.numeric(preds) - 1
    labels <- as.numeric(test$Episode) - 1
    ROC_auc <- performance(prediction(pred, labels), "auc")
    AUC <- ROC_auc@y.values[[1]]
    fold.Result[,start.Index + 10] = AUC
    
    # INCREASE START.INDEX BY 1
    start.Index = start.Index + 1
  }
# AT THE END OF THIS FUNCTION, RETURN THE RESULT FOR THAT FOLD (1 ROW)
  return(fold.Result)
}

#Test_Each_Fold(test, train, trainSynth, result.Cols)
```

